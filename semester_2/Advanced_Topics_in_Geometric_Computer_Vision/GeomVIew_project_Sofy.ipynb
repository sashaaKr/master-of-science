{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71876741",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "#\n",
    "# T E S T   D A T A   G E N E R A T I O N\n",
    "#\n",
    "# this code is not part of mendonca algorithm\n",
    "# and used only for experiment purpose in\n",
    "# order to generate cameras and points\n",
    "# \n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19469cad",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import scipy.optimize as opt\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8462da8c",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "state = pd.read_csv(\"state.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b76bbb3",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(3122787423)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3530a9c",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b0b3011",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def p3t(T,x,y,z):\n",
    "    # apply a Projective 3D Transform\n",
    "    xyz = np.concatenate((x, y, z),axis=1)\n",
    "    column_ones = np.ones((len(x),1))\n",
    "    tmp = T @ (np.concatenate((xyz,column_ones),axis=1)).T\n",
    "    xp = (tmp[0,:]/tmp[3,:]).T\n",
    "    yp = (tmp[1,:]/tmp[3,:]).T\n",
    "    zp = (tmp[2,:]/tmp[3,:]).T\n",
    "    return xp,yp,zp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f382ef79",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def projf(P,x,y,z):\n",
    "#     % PROJ  compute perspective projection (from 3D to pixel coordinates)\n",
    "#     %   pixel positions are returned with floating point precision\n",
    "#     %\n",
    "#     %   See also PROJE\n",
    "\n",
    "    c3d = np.concatenate((x, y, z),axis=1)\n",
    "    column_ones = np.ones((len(x),1))\n",
    "    h3d = (np.concatenate((c3d,column_ones),axis=1)).T\n",
    "    h2d = P @ h3d\n",
    "\n",
    "    c2d = h2d/ h2d[2,:]\n",
    "\n",
    "    u = c2d[0,:].T\n",
    "    v = c2d[1,:].T\n",
    "    return u,v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c44d73d6",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def plot_3d(x,y,z):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(x,y,z)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59dedc89",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def plot_2d(x,y):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.scatter(x,y)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2012564",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def conver_to_col(x):\n",
    "    return np.reshape(x,(len(x),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "699d87d3",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def rcam(A):\n",
    "# RCAM generate a random camera\n",
    "#    generate a random camera pointing to lookp, positioned at an average \n",
    "#    distance ad form the origin, with a std dev of sd \n",
    "#    A is the intrinsic parameters matrix\n",
    "\n",
    "    ad=2.5\n",
    "    sd=0.25\n",
    "    lookp=np.zeros((1,3))\n",
    "    eyep = rng.uniform(-1,1,size=(1,3))-0.5\n",
    "    R = np.zeros((3,3))\n",
    "    eyep = eyep/np.linalg.norm(eyep) * (ad + sd*rng.random(1))\n",
    "\n",
    "    R[2,:] = lookp - eyep/np.linalg.norm(lookp - eyep)\n",
    "    R[1,:] = np.cross(R[2,:],rng.uniform(size=(1,3)))\n",
    "    R[1,:] = R[1,:]/np.linalg.norm(R[1,:])\n",
    "    R[0,:] = np.cross(R[1,:],R[2,:])\n",
    "    Rt = np.concatenate((R,-R @ eyep.T),axis=1)\n",
    "\n",
    "    return A @ Rt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1aad9fd2",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "numberOfViews = 5\n",
    "numberOfPoints = 50\n",
    "imagePoints = np.zeros((numberOfPoints,2,numberOfViews))\n",
    "PPM = np.zeros((3,4,numberOfViews))\n",
    "PPMGT = np.zeros((3,4,numberOfViews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2309c0f5",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def create_fake_points():\n",
    "    data = (rng.uniform(size=(numberOfPoints,3),)-0.5)/(math.sqrt(3)/2)\n",
    "    x = data[:,0]\n",
    "    y = data[:,1]\n",
    "    z = data[:,2]\n",
    "    return x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67761104",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "true_K = np.array([\n",
    "    [800,0,256],\n",
    "    [0,800,256],\n",
    "    [0,0,1]\n",
    "    ])\n",
    "x, y, z = create_fake_points()\n",
    "A = true_K\n",
    "P = rcam(A)\n",
    "invAP = np.linalg.inv(A) @ P\n",
    "lower_line = [[0,0,0,1]]\n",
    "G0 = np.concatenate((invAP, lower_line),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abffe983",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "x,y,z = p3t(\n",
    "    G0,\n",
    "    conver_to_col(x),\n",
    "    conver_to_col(y),\n",
    "    conver_to_col(z)\n",
    ")\n",
    "P = A @ np.concatenate((np.identity(3), np.zeros((3,1))),axis=1)\n",
    "\n",
    "u,v = projf(P,conver_to_col(x),conver_to_col(y),conver_to_col(z))\n",
    "\n",
    "imagePoints[:,0,0] = u\n",
    "imagePoints[:,1,0] = v\n",
    "PPMGT[:,:,0] = P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8b127df",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "for view in range (1,numberOfViews):\n",
    "    # random camera position\n",
    "    P = rcam(A)\n",
    "    # apply world coordinate transformation\n",
    "    P = P @ np.linalg.inv(G0);\n",
    "    # project world points to image points\n",
    "    u,v = projf(P,conver_to_col(x),conver_to_col(y),conver_to_col(z))\n",
    "    imagePoints[:,0,view] = u\n",
    "    imagePoints[:,1,view] = v\n",
    "    PPMGT[:,:,view] = P   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c914b0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A Simple Technique for Self-Calibration\n",
    "Alexander Kruglyak\n",
    "\n",
    "Sofya Zybtsovsky"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51170d2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Introduction\n",
    "The goal of Computer Vision is to compute properties (mainly geometric) of the three-dimensional world from images.\n",
    "One of the challenging problems of Computer Vision is to reconstruct a 3D model of a scene from a moving camera.\n",
    "<br>Possible applications include: navigation of autonomous vehicles, objects recognition, reverse engineering and synthesis of virtual environments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a075be",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In general assumption that the intrinsic parameters of the camera (focal length, image center and aspect ratio) are known. <br>\n",
    "Computing camera motion in this case is a well known problem in photogrammetry, called relative orientation, for which several methods are available.<br>Given all the parameters of the camera, reconstruction is straightforward.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec3f6f3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Camera matrix\n",
    "Camera matrix or (camera) projection matrix is a 3X4 matrix which describes the mapping of a pinhole camera from 3D points in the world to 2D points in an image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2ffd0f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"images/ProjectionMatrix.jpg\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c566a063",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Self-calibration\n",
    "Self-calibration is the process of finding intrinsic parameters of the camera without any actual calibration object:\n",
    "- focal length\n",
    "- image center (principal point)\n",
    "- aspect ratio (pixel skew)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fda3b3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Camera calibration matrix K\n",
    "5 degrees of freedom: 2 for focal length, 2 for offset, and 1 for skewness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073a4653",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"images/K_matrix.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dca2b80",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Approaches to find calibration matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef76ec5d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hartley algorithm\n",
    "- non-iterative algorithm \n",
    "- finds only focal lengths \n",
    "- requires at least 8 conjugate pairs points\n",
    "- ‚Äúheavy‚Äù mathematics calculation (SVD, determinants equation, and many equation, and more...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f12e605",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hartley algorithm - disadvantages\n",
    "- determining only the focal lengths \n",
    "- requires all other internal camera parameters to be known\n",
    "- heavy computations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651d45da",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mendonca - algorithm\n",
    "- extension of Hartley‚Äôs self-calibration technique\n",
    "- Input: 3+ images such as contain at least 8+ correspondence points\n",
    "- Output: <b>all</b> intrinsic parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea72cbd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mendonca - algorithm\n",
    "Based on the theorem of essential matrix E=[t]<sub>x</sub>R:\n",
    "<br><br><center>A real matrix E<sub>3x3</sub> can be factorized as product of a nonzero skew-symmetric matrix <b>t</b> (translation) and a rotation matrix <b>R</b> \n",
    "<br>if and only if \n",
    "<br>E has 2 identical singular values and a zero singular value</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29571739",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mendonca - algorithm\n",
    "E<sub>3x3</sub> =[t]<sub>x</sub>R   <=>    <sup>1</sup>ùûº=<sup>2</sup>ùûº\n",
    "<br><sup>3</sup>ùûº=0\n",
    "<br>algo aims to find 2 singular values (other than zero) \n",
    "that are as close as possible:\n",
    "<br><sup>1</sup>ùûº - <sup>2</sup>ùûº -> 0\n",
    "<br>K is intrinsic matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123e4b97",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mendonca algorithm\n",
    "Input: 3+ images such as each contains at least 8+ correspondence points\n",
    "\n",
    "Output:  K (intrinsic  parameters)\n",
    "\n",
    "1. Init some random matrix K<sub>i</sub> for every image 1‚â§ i ‚â§ n\n",
    "2. Calculate fundamental matrix <b>F</b> for each pair of images (for example via 8-point algorithm with data normalization)\n",
    "3. Calculate essential matrix <b>E</b> for each pair of images (based on F and K)\n",
    "4. Decompose E and find singular values (SVD)\n",
    "4. Calculate error (cost function)\n",
    "6. Minimize error (e.g, via least squares)\n",
    "7. Then cost function reach global minimum: return K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdff6004",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1. Init some random matrix K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a178952",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "initial_K = [true_K[0,0], true_K[0,2],true_K[1,1],true_K[1,2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216091f1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2. Calculate fundamental matrix F for each pair of images (for example via 8-point algorithm with data normalization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfdfc7f0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def calc_fund_matrix(points1,points2):\n",
    "    '''\n",
    "    Takes in 2 arrays of matching points \n",
    "    Return Fundamental matrix computes \n",
    "    using 8 point algorithm\n",
    "    '''\n",
    "#     F, mask = cv2.findFundamentalMat(points1,points2,cv2.FM_8POINT)\n",
    "    F, mask = cv2.findFundamentalMat(points1,points2)\n",
    "\n",
    "    return F \n",
    "\n",
    "Fs = np.zeros((3,3,numberOfViews,numberOfViews))\n",
    "\n",
    "for i in range(numberOfViews):\n",
    "    for j in range(i+1,numberOfViews):\n",
    "        Fs[:,:,i,j] = calc_fund_matrix(imagePoints[:,:,i],imagePoints[:,:,j])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0e1d46",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3. Calculate essential matrix E for each pair of images (based on F and K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "007b049b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_essential_matrix(K,F):\n",
    "    return K.T @ F @ K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5193e5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4. Decompose E and find singular values (SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ce8c0fa",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def decompose_singular_values(E):\n",
    "    _,D,_ = np.linalg.svd(E)\n",
    "    # Singular Values (3rd value, D[3] is 0 according to theorem)\n",
    "    r = D[0]\n",
    "    s = D[1]\n",
    "    return r, s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a4a0fc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5. Calculate error (cost function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63ac43d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<sup>1</sup>ùûº<sub>ij</sub> , <sup>2</sup>ùûº<sub>ij</sub>  - non zero singular values of E<sub>ij</sub> = K<sup>T</sup><sub>i</sub>F<sub>ij</sub>K<sub>j</sub>, such as <sup>1</sup>ùûº<sub>ij</sub> > <sup>2</sup>ùûº<sub>ij</sub>\n",
    "\n",
    "w<sub>ij</sub> - normalized weight factors\n",
    "\n",
    "Minimize cost function:\n",
    "<center><img src=\"images/cost_function.png\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a9ee630",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def mendonca_cost_func(X):\n",
    "    '''\n",
    "    computes Mendonca & Cipolla Cost function to find the Optimal Intrinsic Parameters\n",
    "    Input\n",
    "    X      - Approximate Values of Intrinsics - 1D array with length 5\n",
    "    Output\n",
    "    E    - Computed Cost\n",
    "    '''\n",
    "\n",
    "    K = np.array([\n",
    "        [X[0],0,X[1]],\n",
    "        [0,X[2],X[3]],\n",
    "        [0,0,1]\n",
    "    ])\n",
    "    cost = 0\n",
    "    nof_images = numberOfViews\n",
    "    Den = nof_images*(nof_images-1)/2 \n",
    "\n",
    "    for i in range(0,nof_images-1):\n",
    "        for j in range (i+1,nof_images):\n",
    "            E = calculate_essential_matrix(K, Fs[:,:,i,j])\n",
    "            r,s = decompose_singular_values(E)\n",
    "            cost+= (1/Den) * (r - s)/s\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47649bd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 6. Minimize error (e.g, via least squares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef538c9e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "res = opt.minimize(mendonca_cost_func,x0=initial_K, method='Nelder-Mead')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac8fbe2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 7. Then cost function reach global minimum: return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee7145ee",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[799.98911309   0.         255.99920977]\n",
      " [  0.         799.98828015 255.99955479]\n",
      " [  0.           0.           1.        ]]\n"
     ]
    }
   ],
   "source": [
    "result_K = np.array([\n",
    "    [ res.x[0], 0 ,       res.x[1] ],\n",
    "    [ 0,        res.x[2], res.x[3] ],\n",
    "    [ 0,        0,        1        ]\n",
    "])\n",
    "print (np.matrix(result_K))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91669c74",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mendonca | Advantages\n",
    "\n",
    "- simple mathematical calculation\n",
    "\n",
    "- find all unknown intrinsic camera parameters\n",
    "\n",
    "- always converges to the global minimum\n",
    "\n",
    "- has no bias towards any particular image of the sequence\n",
    "\n",
    "- insensitive to the initialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00450973",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# result_K = np.zeros((3,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adae1b10",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 100966.57497141       0.         -273208.24876514]\n",
      " [      0.          280794.97424055   -6312.28821548]\n",
      " [      0.               0.               1.        ]]\n"
     ]
    }
   ],
   "source": [
    "initial_K = [1,200,1,1]\n",
    "res = opt.minimize(mendonca_cost_func,x0=initial_K, method='Nelder-Mead')\n",
    "result_K = np.zeros((3,3))\n",
    "result_K = np.array([[res.x[0],0,res.x[1]],[0,res.x[2],res.x[3]],[0,0,1]])\n",
    "print (np.matrix(result_K))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f247cc3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Mendonca, Paulo RS & Roberto Cipolla \"A simple technique for self-calibration\" 1999,  University of Cambridge, UK"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
